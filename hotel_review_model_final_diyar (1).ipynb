{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4cab2fe",
      "metadata": {
        "id": "e4cab2fe"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install tensorflow\n",
        "!pip install scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8540229f",
      "metadata": {
        "id": "8540229f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "from transformers import DistilBertTokenizer, TFDistilBertModel\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7ba6ec3",
      "metadata": {
        "id": "c7ba6ec3"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df = pd.read_csv('/content/drive/MyDrive/ input_data.csv')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e7f6e71",
      "metadata": {
        "id": "5e7f6e71"
      },
      "outputs": [],
      "source": [
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "MAX_LEN = 400\n",
        "\n",
        "tokens = tokenizer(\n",
        "    list(df['Review']),\n",
        "    padding='max_length',\n",
        "    truncation=True,\n",
        "    max_length=MAX_LEN,\n",
        "    return_tensors='tf'\n",
        ")\n",
        "input_ids = tokens['input_ids'].numpy()\n",
        "attention_mask = tokens['attention_mask'].numpy()\n",
        "\n",
        "categorical_cols = ['Reviewer_Nationality', 'Hotel_Name']\n",
        "encoders = {col: LabelEncoder().fit(df[col]) for col in categorical_cols}\n",
        "X_categorical = np.stack([encoders[col].transform(df[col]) for col in categorical_cols], axis=1)\n",
        "\n",
        "numerical_cols = ['Hotel_number_reviews', 'Reviewer_number_reviews']\n",
        "scaler = StandardScaler()\n",
        "X_numerical = scaler.fit_transform(df[numerical_cols])\n",
        "\n",
        "y_class = (df['Review_Type'] == 'Good_review').astype(int)\n",
        "y_reg = df['Review_Score']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d219525e",
      "metadata": {
        "id": "d219525e"
      },
      "outputs": [],
      "source": [
        "(train_input_ids, val_input_ids,\n",
        " train_attention_mask, val_attention_mask,\n",
        " train_categorical, val_categorical,\n",
        " train_numerical, val_numerical,\n",
        " y_class_train, y_class_val,\n",
        " y_reg_train, y_reg_val) = train_test_split(\n",
        "    input_ids, attention_mask, X_categorical, X_numerical,\n",
        "    y_class, y_reg, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3814d11",
      "metadata": {
        "id": "e3814d11"
      },
      "outputs": [],
      "source": [
        "\n",
        "text_input_ids = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='input_ids')\n",
        "text_attention_mask = layers.Input(shape=(MAX_LEN,), dtype=tf.int32, name='attention_mask')\n",
        "numerical_input = layers.Input(shape=(X_numerical.shape[1],), dtype='float32', name='numerical_input')\n",
        "\n",
        "categorical_inputs = []\n",
        "categorical_embeddings = []\n",
        "for i, col in enumerate(['Reviewer_Nationality', 'Hotel_Name']):\n",
        "    num_classes = len(encoders[col].classes_)\n",
        "    input_cat = layers.Input(shape=(1,), dtype='int32', name=f'{col}_input')\n",
        "    embedding = layers.Embedding(input_dim=num_classes+1, output_dim=8)(input_cat)\n",
        "    embedding = layers.Flatten()(embedding)\n",
        "    categorical_inputs.append(input_cat)\n",
        "    categorical_embeddings.append(embedding)\n",
        "\n",
        "tabular_concat = layers.Concatenate()(categorical_embeddings + [numerical_input])\n",
        "tabular_dense = layers.Dense(32, activation='relu')(tabular_concat)\n",
        "\n",
        "bert_model = TFDistilBertModel.from_pretrained('distilbert-base-uncased')\n",
        "bert_output = layers.Lambda(\n",
        "    lambda x: bert_model(x[0], attention_mask=x[1]).last_hidden_state[:, 0, :],\n",
        "    output_shape=(768,), dtype=tf.float32\n",
        ")([text_input_ids, text_attention_mask])\n",
        "\n",
        "merged = layers.Concatenate()([bert_output, tabular_dense])\n",
        "x = layers.Dense(64, activation='relu')(merged)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(32, activation='relu')(x)\n",
        "\n",
        "output_class = layers.Dense(1, activation='sigmoid', name='classification_output')(x)\n",
        "output_reg = layers.Dense(1, activation='linear', name='regression_output')(x)\n",
        "\n",
        "model = keras.Model(\n",
        "    inputs=[text_input_ids, text_attention_mask] + categorical_inputs + [numerical_input],\n",
        "    outputs=[output_class, output_reg]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss={\n",
        "        \"classification_output\": \"binary_crossentropy\",\n",
        "        \"regression_output\": \"mse\"\n",
        "    },\n",
        "    loss_weights={\n",
        "        \"classification_output\": 0.5,\n",
        "        \"regression_output\": 0.5\n",
        "    },\n",
        "    metrics={\n",
        "        \"classification_output\": \"accuracy\",\n",
        "        \"regression_output\": \"mse\"\n",
        "    }\n",
        ")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9571c9b4",
      "metadata": {
        "id": "9571c9b4"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x={\n",
        "        \"input_ids\": train_input_ids,\n",
        "        \"attention_mask\": train_attention_mask,\n",
        "        \"Reviewer_Nationality_input\": train_categorical[:, 0],\n",
        "        \"Hotel_Name_input\": train_categorical[:, 1],\n",
        "        \"numerical_input\": train_numerical\n",
        "    },\n",
        "    y={\n",
        "        \"classification_output\": y_class_train,\n",
        "        \"regression_output\": y_reg_train\n",
        "    },\n",
        "    validation_data=(\n",
        "        {\n",
        "            \"input_ids\": val_input_ids,\n",
        "            \"attention_mask\": val_attention_mask,\n",
        "            \"Reviewer_Nationality_input\": val_categorical[:, 0],\n",
        "            \"Hotel_Name_input\": val_categorical[:, 1],\n",
        "            \"numerical_input\": val_numerical\n",
        "        },\n",
        "        {\n",
        "            \"classification_output\": y_class_val,\n",
        "            \"regression_output\": y_reg_val\n",
        "        }\n",
        "    ),\n",
        "    batch_size=16,\n",
        "    epochs=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05805c10",
      "metadata": {
        "id": "05805c10"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(history.history['classification_output_accuracy'], label='train acc')\n",
        "plt.plot(history.history['val_classification_output_accuracy'], label='val acc')\n",
        "plt.title('Classification Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(history.history['regression_output_mse'], label='train mse')\n",
        "plt.plot(history.history['val_regression_output_mse'], label='val mse')\n",
        "plt.title('Regression MSE')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(history.history['loss'], label='train loss')\n",
        "plt.plot(history.history['val_loss'], label='val loss')\n",
        "plt.title('Total Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}